I'm still a little confused about using my computer's terminal versus my ide terminal.
It seems more effective to use the ide one, but I admit I am relatively new to the whole thing.
The term fork in the context of GitHub basically means copy

my aws ip addy
http://184.73.198.144/
command to remote shell:
ssh -i "C:\Users\becca\OneDrive\Documents\School\CS260\---" ubuntu@260dreams.click
Note also that I am unsure whether my computer actually has ubuntu at all. Not sure if I want to subscribe, either. 
-The class instruction mentioned nothing about it, which could either mean I don't need it, or they expect everyone to already have it.

Commands for the windows terminal:
pwd = Present working Directory
cd = change directory
ls = List files
-la = (will list in long format)
mkdir/rmdir=make/remove directory
rm/mv/cp=remove/move/copy files
find = find files
cat = output file contents
wc=wordcount
kill = kill running process
sudo = execute command as admin
ssh = secure shell
ctrl+c = kill current command
>/>> = redirect output to file. single overwrites, double appends
| = pipes output from left command into right command

http = hypertext transport protocol (non-secure)
https = secure version (should always be used/supported nowadays (in anything you build)) (web certificate necessary) (port 443)
when using non-secure connections, anyone with access to the network traffic can capture all data sent in either direction (bad)
SOA = start of authority - a record that provides contact info about the owner of the domain name
the handshake exchanges web certificate which identifies domain name of server creating the secure connection.
the browser compares the certificate domain name to the one repped in the url and if they don't match or if the certificate is invalid, you get a warning display
Web Certificates are generated by a third party. the issuer is responsible for verifying the owner.
HTML = HyperText Markup Language was originally created as a publishing format for web pages, now reps either SPA or MPA
SPA = Single Page Application
MPA = Multi-page application - a group of hyperlinked pages

always include the <!doctype> brackets when coding an html
*it is common to name the main file index in htmls 
an html file is coded by <body>, which has three sections: header, main, and footer. Each section may contain other structural content
A hyperlink in HTML is represented with an anchor (a) element that has an attribute containing the address of the hyperlink reference (href). 
A hyperlink to BYU's home page looks like this: <a href="https://byu.edu">Go to the Y</a>

Since we now have JavaScript to supplement our htmls, we don't need to include a "form" element, though we can

Cascading Style Sheets (CSS)
CSS converts structure and content of html to a vibrant, responsive experience
concerned with defining rulesets or rules
rule is comprised of a Selector that selects elements to apply the rule to and Declarations that represent the Property to style  w the property value
the style element should appear in the Head element of the doc
elements inherit the rules applied to their parents
CSS defines everything as boxes
<div>s are automatically defined as boxes in html, too. Can of course be changed from CSS
CSS flex display (display: flex) is useful when you want your content to react to the window size/orientation.

Bootstrap CSS package is good to use for when JS is needed. Bootstrap is very common to use
to  include Bootstrap in your application using NPM you would run the following from your console: npm install bootstrap@5.2.3 (ver num may need to be updated from time to time)

JavaScript = most commonly used language
use keyword "let" or "const" (depending if you want it constant or able to change) to define variables (not "var")
objects can change type based on what you assign to them, they may not necessarily remain the way they were defined (will adapt)
JS supports the regular mathmatical operators (triple === for equality(or !== for not))
    at least for number vars. For strings, only + and ===
    double == is technically usable but can give unexpected results with the complex defining rules.
Can define a string with ', ", or `

Unicode is a thing that helps you support other languages

functions begin with keyword "function"
and, yes, you can declare functions from inside other functions
These two functions are the same:
    // standard function syntax
    a.sort(function (v1, v2) {
        return v1 - v2;
    });
    // arrow function syntax
    a.sort((v1, v2) => v1 - v2);
Return statements with arrow function:
    () => 3;
    // RETURNS: 3
    () => {
        3;
    };
    // RETURNS: undefined
    () => {
        return 3;
    };
    // RETURNS: 3

debounce functions are good for efficiency. They will restrict execution of a function to once per /time-slot/. The time will reset every time the debounce function is called

&nbsp = non-breaking space character. will add a space when typed

JavaScript Object Notation (JSON): can be converted to and from Javascript (but does not require JS to be processed)
ex: let o = {number=1,value="carrot",features=['orange','root']};
A JS obj reps a collection of name-value pairs referred to as properties
JS Objects (not to be confused with your avg obj) can be created with the new operator/keyword
Object-literal syntax allows you to provide initial composition of obj
creating a class signifies intent to create a reusable component
can add new properties to a JS obj dynamically, or after defining it
Classes have an explicit constructor
properties and functions of classes can be made private with a '#' in front
    ->use the # every time you reference it, as well
extends can create an inheritance.
    class employee extends person {}
a parent's functions can be accessed using keyword 'super'
Regular Expressions are built in to JS
use a reg exp to find text in a string
create a reg exp using the class constructor or a reg exp literal
turn the last parameter into a rest parameter by leading it w ... this allows you to call the funtion with any number of parameters, which are all automatically combined into an array
handle exceptions with try/catch and throw syntax
remember you can also have a 'finally' block after a 'try' block that will always execute no matter whether an exception was thrown
restrict exceptions to exceptional situations, not things that are going to be happening often. Just debug your code, dude
fallbacks help handle exceptions and provide something to return even when an exception is thrown
destructuring != destructing
destructuring lets you pull items out of something like an array or object
^tricky syntax
Scope is the variables that are visible in the context of execution.
    Global- visible to all code
    Module- visible to all code running in a module
    Function- visible withing a function
    Block- visible within a block of code delimited by curly braces
Once again, don't use term var unless in a very particular situation... it ignores block scope
three diff contexts 'this' can refer to:
    Global- referenced from outside a function, context for runtime enviro
    Function- from inside a function, refers to obj that owns the function
    Object- from inside an object, refers to same obj
JS modules allow for partitioning and sharing of code
JS has module support for ES6. 
Node.js modules=CommonJS modules JS modules=ES modules
modules create a file-based scope for their code, so you must export objects from one file and import them into another
cannot access JS contained in a module that your nonmodule JS is executing in
from html. specify you are using an ES module
    <script type="module"></script>

DOM= Document Object Model, an object representation of HTML elements
^ a tree-structured rep of the html
property textContent sets the child text for an element
calling .textContent allows you to change the text in an element

JS executes as a single thread-- ie there is only ever one piece of code executing at any given time
However, you can run the same program in parallel- asynchronously- with a Promise, which can be in any of three states: Pending, Fulfilled, and Rejected
Create a promise by calling the Promise object constructor and passing in an executor function
You can set the state to Fulfilled or Rejected with Resolve or Reject commands/methods
once a Promise has been resolved, handle it like unto an exception. Catch if the promise was rejected, Then is called if Promise==Fulfilled, and Finally is always called once the processing is completed. 
Observers are similar and also allow asynchronous processing

await keyword wraps execution of Promise. Blocks it until the state moves to Fulfilled (or throws an exception if the state moves to Rejected)
can only call Await at the top level of JavaScript, or in a function defined with keyword Async. This keyword transforms the functions so it returns a Promise to resolve whatever value was previously returned. ie, it turns any function into an asynchronous function
Using await when calling a function defined with async will return the result of the promise defined (or implicitly defined) within the function. Not using 'await' will return the whole promise object
a promise can be equated to a then/catch chain or try/catch block with an await in there

When debugging:
write a block of code, then step through and debug the block (before writing the next one)
console.log() functions output the state of the code as it executes. This can be an easy way to help debug
You can also debug in the browser console
Source tab (in browser debugger) shows the code. Can click to highlight a line which will then be a breakpoint. Just refresh the page and program will stop there.

keyword 'defer' will delay code until the end
chmod +x deploy.sh <-command to make a script executable
chmod changes a file's mode bits to control the access rights to a file
DNS = Domain Name System
You cannot use 'undefined' in JSON. Or single quotes.
TLD = Top level domain (the final section of a domain name, such as click, com, org, etc)
a root domain is a website name, like cs260.click, and a subdomain is a sub of that, like simon.cs260.click

the internet is an interconnected web of wires (and wireless wires) throughout the world
When one device wants to talk to another, it needs an IP address. Users often prefer symbolic names over the number address, called a domain name. You can convert a domain name  by looking it up in the DNS and using the command dig
devices and websites both have IP addresses
traceroute command will allow you to see route of requests from requester to destination
traceroute may not always show the exact same route
ISP = Internet Service Provider
TCP = Transmission Control Protocol
IP= Internet Protocol
TCP/IP Layers: Application (functionality), Transport (moving), Internet (establishing connections), and Link (physical connections)

a web server is a computing device that is hosting a seb service and knows how to accept incoming connections
in early days, this was a massive, complex, expensive software program
now, most programming languages include libraries that provide the ability to make connections and serve http
it is common to find multiple services running on the same device. every network device allows for seperate network connections through unique port numbers. Each service starts on a diff port
This can be confusing, so we may introduce a service gateway that begins on the https port 443 and can redirect us to other services.
*Caddy is our current gateway
web services providing a single function are microservices. These can be managed independently from a larger system. They can also make stateless copies based on user demand.
In serverless functionality, the server is removed from the architecture; you write a function speaking HTTP that is loaded through the gateway mapping a request to that function.

the owner of a root domain can create any number of subdomains off the root domain. each sub may use a diff ip addy.
use command whois to find information on a particular domain name
address (A) and Canonical name (CNAME) records map domain names to ip addresses. A's straight map it together; cname maps one domain name to another domain name, which acts as an alias (such as mapping byu.com to byu.edu)
Authoritative Name Servers assiciate domain names with ip addys
Time to Live (TIL) is a setting for domain records. 

the html/css/js/image files that run on the browser are the Frontend of your application
Currently, my app is loaded from my web server and runs on the user's browser
frontend uses https protocol to request the app files
can make requests to anywhere from frontend js (often with a fetch function)
*to build a full stack web app, create your own web service
the functionality provided by your web service reps the Backend of your app
endpoints are the functions provided by a web service. aka APIs
access endpoints from frontend js with the fetch function
backend provides static files making up the frontend as well as service endpoints called by the frontend
Fetch function can be used to request data either from the backend web service (provided files) or from other web services

URL = uniform resource locator
^location of a web resource
there are many parts to a url, and most of them are optional
<scheme>://<domain name>:<port>/<path>?<parameters>#<anchor>
this is the format of a url. the only required parts are the scheme and domain name
scheme: protocol required to ask for the resource. (usually https)
domain name: name that owns the resource rep'ed by the url
Port: specifies numbered network port used to connect to domain server (default 443 for https)
Path: path to resource on domain
Parameters: rep a list of key-value pairs, usually provides additional qualifiers on resource rep'ed by the path. sometimes called query str
Anchor: reps a sub-location in the resource. sometimes called fragment or hash ID
URN = Uniform Resource Name
^ a unique resource name not specifying location info
URI = Uniform Resource Identifier
^ a gen identifier that could refer either to a url or urn (usually a url, which you should generally be using anyway)

When connecting a device to the internet, you need both an IP address and a numbered Port.
port numbers allow a single device to support multiple protocols (ie http, https, ssh, etc) and diff types of services (search, authenticate,...)
HTTPS port = 443
HTTP port = 80
SSH port = 22
IANA = internet governing body
ports 0-1023 are standard protocols and should be avoided if not being used the standard way
ports 1024-49151 rep ports assigned to requesting entities and are commonly used by internal device services
ports 49152-65535 are used to create dynamic connections to a device
when (my) caddy receives a port 80 request, it auto-redirects to port 443
on your web server, you can have as many services running as desired, but each must use a diff port to communicate

http is how the web talks. web browsers make requests to web servers through http protocol
web client = web browser
browser makes http request and server generates http response
you can see the http exchange in the browser debugger or by using a console tool like curl (tool must be accompanied by further commands)
an http request has syntax like
    <verb> <url path, parameters, anchor> <version>
    [<header key: value>]*
    [<body>]
example:
    GET /hypertext/WWW/Helping.html HTTP/1.1
    Host: info.cern.ch
    Accept: text/html
The accept key/value pair specifies the type of resources the client (specified in the host key/val pair) will accept
the syntax of the response looks like:
    <version> <status code> <status string>
    [<header key: value>]*
    [<body>]
first line example:
    HTTP/1.1 200 OK
Some common verbs:
get - get requested resource
post - create new resource
put - update resource
delete - deleta resource
options - get metadata on resource
Status codes: these are partitioned into 5 blocks or types
1xx- informational
2xx- success
3xx- redirect
4xx- client errors (request is invalid)
5xx- server errors (request cannot be satisfied)
http headers specify data about a request or response (such things as security, caching, data formats, and cookies)
some common headers: Authorization, Accept, Content-Type, Cookie, Host, Origin, Access-Control-Allow-Oriigin, Content-Length, Cache-Control, User-Agent
format of an http req/resp body is defined by Content-Type header
http is stateless, meaning that any given request knows nothing of previous or future requests. However, states can be tracked with the cookie, something generated by the server and passed to the client as a header
the client must cache the cookie and return it as an http header
cookies allow a server to remember a user's preferences or credientials.

Node.js was the first successful app for deploying js outside a browser
*created by Ryan Dahl in 2009, commonly referred to as Node
>changed mindset of js from browser tech to server tech
>js can power entire tech stack
browsers run js using a js interpreter and execution engine (such as V8)
*Node took the V8 engine and runs it in a console app
-v = version
-e = execute
real work, requires executing many js files. you can do this by creating a single start js file that refs the others, then calling the start file in your node execution call (ex: node index.js)
you can use pre-existing packages of js to accomplish common tasks. Just install the package locally using the Node Package Manager (NPM) and then include a "require" in your statement referencing the package name
NPM has a massive repo of packages. You can search them on the NPM website. But before using NPM you need to init your code to use it (npm init (you can include -y here to skip a questionnaire about your project))
*You can also uninstall packages
when you install package dependencies, npm will create an additional file and directory to accompany it in your project directory. Put these in your .gitignore file rather than including them in your source control
when you clone repos, the first thing you should do is command "npm install" to get all the packages referenced.

Node is good for little projects and quick content. however, to be a production-lvl/ready app, you need a framework with greater functionalaity more easily implemented
Node package Express provides support for: routing requests for service endpoints, manipulating http requests with JSON body content, generating http responses, and using middleware to add functioality
*created by TJ Holowaychuk and maintained by open.js foundation
Express revolves around creating and using http routing and middleware. Create an express app by using npm to install the express package and then calling the express constructor
define routes in express that call functions based on an http path in order to implement an http endpoint. express regognize http verbs,such as get
 ex:
    const express = require('express');
    const app = express();
    app.get('/store/provo', (req, res, next) => { res.send({name: 'provo'});});
get takes two parameters: a url path matching pattern and a callback function (invoked when pattern matches). the callback function, in turn, takes 3 parameters: request, response, and next (routing function to be called if this one wants another function--optional)
the Express app compares the routing function patterns in the order they are added to the app object.
Express supports path parameters by prefixing parameter names with a colon. It then creates a map of path params and populates it with the matching values found in the url path. You can then ref the params using the req.params object
ex: replace res.send({name: 'provo'}); from prev example with:
    res.send({name: req.params.storeName}); (rather than hardcoding to 'provo')
you can see the results created with 'curl' in the command line
examples of route functions:
    // Wildcard - matches /store/x and /star/y
    app.put('/st*/:storeName', (req, res) => res.send({update: req.params.storeName}));
    // Pure regular expression
    app.delete(/\/store\/(.+)/, (req, res) => res.send({delete: req.params[0]}));
standard mediator/middleware design has two pieces: a mediator and middleware
middleware reps componentized pieces of functionality
mediator loads middleware components 
Express is the mediator, middleware functions are the middleware
Express comes with standard middleware functions that provide functionality like routing, authentication, CORS, sessions, cookies, logging... some are provided by default and some must be installed with npm. You can also write your own.
a middleware function looks like a routing function (because routing functs are middleware-- however, they are only called if associated patterns match. most middleware functs are always called for every http request)
    function middlewareName(req, res, next)
You should usually be calling the next function at the end of your processing (last line of your function) so that the next middleware funct can execute
ex: writing a middleware function:
    app.use((req, res, next) => {
    console.log(req.originalUrl);
    next();
    });
ex: using builtin middleware:
    app.use(express.static('public'));
middleware can be added to handle errors, just add another param at the front of the param list for the 'err'

Localstorage can only save strings, so to save something to local storage, it must be a string. JSON.stringify is handy for this. To pull it out of local storage, we need it out of the string, so JSON.parse is good for that.
Use 'let' variable when you know that your variable may change over time (as opposed to 'const', which you generally will use)
Database stores data onto a web server (into the cloud,more or less), whereas local storage puts it on the computer, so what is stored in a database can be accessed from other computers

once, javascript could make requests from one domain while displaying a website from another domain. these are cross-origin requests
to fight this, the SOP (Same Origin Policy) was created. it only allows JS to request from a domain that it is currently in. Cross Origin Resource Sharing (CORS) allows the client to specify the origin and let the server respond with what’s allowed. server may say all origins allowed, such as if it’s a gen serv. provider, or only a specific origin is allowed, like if they’re a bank. If server does not specify, browser assumes same origin
With CORS, it is the browser protecting the user from accessing an authentication service from the wrong origin. CORS is meant to alert the user something is wrong, but hackers can still ignore an Access-Control-Allow-Origin header 
When you make requests from your own web services, you won’t violate SOP (obviously)
Trying to (fetch) request from another website may cause CORS to fail your request (403 code), if it doesn’t have that access control header
*so test websites you want to use before using them. Make sure they respond with ‘*’ or they can’t be used.

web services provide interactive functionality, such as: authenticate users and track their session as well as connect to others and such. provide, store, analyze data. an easy-to-use application will be more successful.
creating a sequence diagram may help you see how objects interact (or are meant to interact)
web services are usually provided over http. remember http verbs such as get/post/put/delete/etc, which mirror web service actions
service endpoints are often called Application Programming Interface (API), which can refer either to a singular endpoint or a collective.
a web service is usually divided into multiple service endpoints. each one provides a single functional purpose. 
remember the grammar of an endpoint: since it's http, act on a resource with an http verb. Also make sure the referenced resource is clearly readable in whatever url you provide. Also make it discovereable, for instance, if you have many endpoints, you can make them point to each other. also make them compatible-- so that you can add new functionality without breaking existing clients. note also this will usually mean the ignoring of your endpoint clients toward anything misunderstood
by adding representations, you add functionality
keep your endpoints simple and focused on the primary resources of your application, which resources focus on the resources of your system rather than the data structures and devices used to host them. Endpoints should only do one thing
create, use, and maintain documentation of your service endpoints. consider making use of such tools as Open API Specification which take care of that for you and build for you a sandbox of experimentation. Create a draft of your initial endpoint documentation

RPC = Remote Procedure Calls
RPC expose service endpoints as simple function calls.
when used over http, usually leverages the http verb "POST" 
maps directly to function calls that exist within the server.
*exposes inner workings of a service
REST = Representational State Transfer
REST attempts to take advantage of foundational principles of http
created by a contributor to http
rest verbs always act upon a resource
GraphQL focuses on manipulation of data (rather than the function call of RPC or the resource of REST).
a query that specifies desired data and how to join/filter it
Instead of calling for each detail one by one, GraphQL can request all desired information in the form of one big JSON response
helps remove logic for parsing endpoints and mapping requests to resources because there is only one endpoint(the query)
*client now has power to consume resources of server--no clear boundaries
common GraphQL packages provide support for schema implementations with database adaptors for query support.

when you run a program from the console, it will terminate when you close the console (or when the computer restarts).
to keep programs running after shutdown, register is as a 'daemon'--something always working in the background
Process Manager 2 = PM2, an easy way to start/stop your service
*PM2 is already included on my service as a part of AWS
*you can see it in action by SSH-ing into the server and running 'pm2 ls'
if you want to set up another subdomain:
    add rule to caddyfile to tell how to direct requests for said domain
        ssh into server -> copy section for startup and alter it to rep the sub and give it a different port num
        restart caddy to load new settings
    create directory and add files for web service
        copy startup directory to a dir. that reps the purpose of your service (use ctrl+c to stop service)
        start up web service listening on [port 5000]: 'node index.js 5000'
        now you can access service through browser, or curl: 'curl [url]'
    configure pm2 to host service
        when you close your ssh session, all processes you began will be stopped (including your web service). Hence the need for something always on in bg (daemon).
        cd into your service directory, run 'pm2 start index.js -n [subdomain] -- 5000' and 'pm2 save'

remember the frontend is the part everyone sees and works with, tha backend is the code
you can press f5 to run debug (stop debugging by shift+f5)
consider nodeman package which will restart node every time you save a change you've made. if you install it your debugger will run with that instead of node.js

it is critical to separate where you develop your app from where you make the release publicly available (and there are usually more than these 2 environments). Developers don't usually have access to production environments, and there are usually many tests and staging that occur before an application is deployed
you should never consider the production environment as a place to develop or experiment
automated deployment processes (as we will be using) are reproducible. You won't accidentally delete or misconfigure something in your files.
our deployment scripts will change with the new technologies that we employ
-k parameter provides the credential file necessary to access your production environment (pem key)
-h parameter = domain name of production environment
-s parameter reps name of app you are deploying (ie simon, startup)
first part of deployment script parses command line parameters
next, the script copies all applicable source files into distribution directory (dist) (it will clear the target directory to make the new copies via secure shell(ssh))
the dist will then be copied to the production enviro via secure copy program (scp)
then use ssh again to install node packages and restart service daemon
lastly, delete dist

web apps often need to upload files from frontend app in the browser to the backend service, which can be accomplished by using HTML input element of type file on frontend and npm package Multer in backend
Multer is not the only package to use, but it is a common one. It reads the file from the http request and enforces size limits, as well as stores the file in the "uploads" directory. It also handles requests for static files, errors, and provides a get endpoint to serve up a file from the uploads directory
It is not a very good idea to store your files on your server becasue 1. there isn't much space, 2. servers are transient, 3.server storage is not usually backed up, and 4. multiple application servers might mess you up. Use a dedicated storage service instead.

web apps usually need to store files associated with the app or its users, such as images, user uploads, documents, movies, and such. files usually have an id, metadata, and the bytes of the file. It tends to be overkill to store these in a database service.
It's usually a bad idea to store these on the server because, again, 1. you have limited space, 2. servers are transient/temporary, and 3. backup copies are not provided here
use a storage service designed for production storage
one of the most popular of these services is AWS S3, which has these perks:
    unlimited capacity      only pay for what you use       global access
    keeps multiple copies       can version the files       performant
    supports metadata tags      can make files publicly available from S3
    can keep files private/accessible only to application
if using S3, learn to use AWS SDK
steps: create S3 bucket to store data, get credentials so app can access bucket, use credentials in app, use SDK to edit files from bucket (*don't include the credentials in your code)

web applications often need to store application/user data, such as profile, structure, gameplay info, usage, billing, etc, persistently.
SQL databases are the historically used things, but now we tend to use NoSQL solutions, such as Redis, MongoDB, Neo4J, and ElasticSearch, which specialize in certain aspects of a program
*we will be using MongoDB, which uses JSON objects as its core model
consider a collection as a large array of javascript objects
Mongo has no strict schema requirements
to add a new field to a Mongo collection, insert the field into the document(s) as desired. If it doesn't match, then the document won't match the query criteria when called upon.
install Mongo, make a client object (with username/password/hostname), then insert/query for documents. When inserting a document, if the database collection of intended destination does not exist, it will be created.
to query for documents, use the 'find' function on the collection obj. Note that find is asynchronous so we use 'await' (afterwards) to ensure the promise(s) have resolved before moving on. If you do not supply parameters to 'find', you will receive all docs in collection
with a managed data service, your service will grow or shrink to support the desired capacity-- in short, take care of itself.
*we will use data service Atlas with MongoDB

to remember a user's data, we need a way to uniquely associate said data with a particular credential. ie, authenticate a user (such as with an email and password). You can remember this authentication by storing an authentication token on the user's device, such as a cookie.
you must also determine what a given user is authorized to do on your app. You can store authorization power with user information. A complex app will usually have much authorization representation that controls a user's access to every part of it.
authentication and authorization can be complex and are prime targets for hackers.
many service/package developers have created solutions to help you
authorization services use standard protocols like OAuth, AML and OIDC.
SSO = Single Sign On, a concept allowing a user to use the same credentials for multiple web apps (such as, using your google credentials on other sites)
Federated login allows a user to log in once and immediately reuses your auth token to log in to multiple sites (such as logging in to gmail and you can get into drive and docs without logging in for each one)

---

web frameworks provide tools for completing common tasks to make your application building easier (such as modularizing code, simplifying reactivity, etc)
some frameworks go beyond the standard html/javas/css and create new hyprid formats that combine such things into one file (such as React JSX, VUE SFC, and Svelte.)
Vue combines all three and is repped by a template element
Svelte also combines all three but requires a transpiler to generate code
React combines html and javascript (not css)
an angular component defines what js, css, html are combined, which keeps a strong seperation of files that are usually grouped together

React provides a powerful web programming framework. its name comes from its focus on making reactive web page components.
*was created by Jordan Walke for Facebook
*abstracts html into a js variant "JSX", which can be converted back into a valid html and js using Babel, a preprocessor.
the React.createElement() function will generate DOM elements and monitor them for changes (which React will then, um, react to)

React components allow you to modularize your functionality, which allows underlying code to directly represent user-interactive components.
*also enable code reuse
*generate user interface (with "render" function)
    JSX
        <div>
            Component: <Demo />
        </div>
    React Component
        function Demo() {
            const who = "world";
            return <b>Hello {who}</b>;
        }
    Resulting HTML
        <div>Component: <b>Hello world</b></div>
React components allow you to pass info to them as element properties and will receive these as a constructor and display them when it renders.
    JSX
        <div>
            Component: <Demo who="Walke"/>
        </div>
    React Component
        function Demo(props) {
            return <b>Hello {props.who}</b>;
        }
    Resulting HTML
        <div>Component: <b>Hello Walke</b></div>
Components can have an internal state, created by calling React.useState, which is a hook function returning a var containing current state and a function to update that state
note you can use JSX even w/o a function-- a simple var repping jsx will work anyplace you would otherwise provide a component
React currently supports class style components as well as function style ones (diff:properties are loaded on constructor and state is set)
A component's properties and state are used by React framework to determine interface reactivity. Reactivity controls how a component reacts to user actions.

web programming is complex. We made a series of tools to help with that.
some common pieces in a web app tool chain:
    code repository, linter(warns of non-idiomatic code usage), prettier(formats to standard), transpiler(compiles into different formats), polyfill(generates code for supporting older browsers), bundler(packages code into bundles), minifier(removes whitespace), testing(automated tests), deployment

using a Command Line Interface (CLI) saves you the trouble of configuring toolchain parameters and gets you a quick start
if using jsx code in your file, you should probably use .jsx as your file extension (as opposed to .js)
'npm run dev' bundles code to a temporary directory, and 'npm run build' will deploy it to a production environment (also creating a new 'dist' directory for the server)

The React Router needs to be set up and will usually be imported in index.js (wrapping around app component). React does not have a standard router package
you generally define your routes in the app component/top level of your app but can be done anywhere.
Route uses "link" as the anchor tag, and uses "to" as a prop instead of "href"
Dynamic Routing offers a way to provide routes w/o hardcoding each one (just put a : in front of the dynamic parameter)
You'll usually want to use 'useParams()' hook when you have a dynamic route
In the olden days, position determined importance, but now there is an algorithm in react router that will determine which route you want more based on which is most specific
an * will match anything and is good for something like an error page. The * will always be less specific than anything else and so won't override your other routes.
Routes can be nested for a cleaner look, just make a parent route that has the path set to the shared path for all the child components
if you pass an element prop to a parent route, it will render that component for every child route, so you can put a shared nav or other components with ease
The Outlet component is a placeholder of sorts and will render your page's current content, which helps with your sharing of code
you can also share layouts by wrapping child components when a parent route only defines an element and no path (this can be useful if your routes don't have similar paths but you want the same layout on both)
Outlet comps can also take a context prop which will work like React context
You may also use multiple route components at the same time (as two seperate, or as nested)
    Seperate Routes might be used if you want two different sections of content that both depend on the url of the app, through an 'aside'
    Nested Routes are common if you have lots of routes and so you move similar ones into their own files (create a new comp to call them from the [function] you store them in. don't forget to use *)
     <Routes>
     <Route path="/books/*" element={<BookRoutes />} />
     </Routes>
    export function BookRoutes() {
  return (
    <Routes>
      <Route element={<BookLayout />}>
        <Route index element={<BookList />} />
        <Route path=":id" element={<Book />} />
        <Route path="new" element={<NewBook />} />
        <Route path="*" element={<NotFound />} />
      </Route>
    </Routes>
Note you can use a JS object instead of JSX (this involves useRoutes())
in link navigation, any route that starts with a '/' is an absolute route
besides 'to', there are three other keywords (props) used in links.
    Replace-- a boolean that can command a replacement of the current page in browser history
    reloadDocument--a boolean that can call for a full page refresh
    state - allows you to pass data with your link not appearing in the url
NavLink is a component identical to the link comp but is specifically for showing active states on links. if the 'to' property matches the current url, the link is considered active
the 'end' property of a navlink can be used to specify if you don't want parent route links to also count as active
Navigate - a simple comp that, when rendered, will automatically redirect the user to the 'to' property
    <Navigate to="/"/>
it also shares the other props of the link comp
useNavigate() takes no params and returns a navigate function, which will need to be fed parameters for 'to' and 'replace' (or can simply be fed a number of pages in the history to navigate through, pos or neg depending if you want to go forward or backward)
Search parameters are the params coming after a ? in the url

React enables reactivity with three major pieces: props, state, render
react parses jsx when it is rendered and creates a list of refs to comp state/prop objects, then monitors changes to those objects
keyword 'export' allows [functions] to be available outside of the file in which they're defined.
keyword 'default' tells other files using this [function] that this is the main function in the file.